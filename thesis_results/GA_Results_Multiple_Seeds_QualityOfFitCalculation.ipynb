{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f9597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: UserWarning: To obtain optimal results install the Cython 'munkres' module at  https://github.com/jfrelinger/cython-munkres-wrapper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scipy.stats as st\n",
    "\n",
    "import networkx as nx\n",
    "import gmatch4py as gm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\\\\Git\\\\complex_stylized_supply_chain_model_generator\")\n",
    "\n",
    "from complex_toy_model_graph_generator import ComplexSimModelGraph\n",
    "from structure_model_composer.set_locations_of_structures import plot_graph_locations_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f69f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}\n",
    "x={}\n",
    "y={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31849ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #upload all percentages\n",
    "# #directory = \"C:/Users/IvS/Documents/2.Papers/2.WinterSim_ParametricCalibration/Results/Results_Missing_Full\"\n",
    "# technique = \"ga\"\n",
    "# sparseness = \"bias\"\n",
    "# directory = f\"./{technique}_{sparseness}\"\n",
    "# #Over folders\n",
    "# for folder in os.listdir(directory):\n",
    "#     if not folder.startswith('.'):\n",
    "#         new_dir = directory+\"/\"+folder\n",
    "#         if os.path.isdir(new_dir):\n",
    "#             for filename in os.listdir(new_dir):\n",
    "#                 if filename.endswith(\".pkl\"):\n",
    "#                     f = new_dir+\"/\"+filename\n",
    "\n",
    "#                     key = filename.split('_')[:2]\n",
    "#                     key = \"_\".join(key)\n",
    "\n",
    "#                     with open(f, \"rb\") as file:\n",
    "#                          info = pickle.load(file)\n",
    "                        \n",
    "#                     seed = info[\"Model_info\"][\"parameters\"][\"seed\"]\n",
    "                    \n",
    "#                     try:\n",
    "#                         data[seed][key] = info\n",
    "#                     except KeyError:\n",
    "#                         data[seed] = {key: info}\n",
    "# for k, v in data.items():\n",
    "#     data[k] = dict(sorted(data[k].items(), key=lambda item: int(item[0].split('_')[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7eb3e6-c9fe-43ae-928c-6cda73cfa4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload all percentages\n",
    "#directory = \"C:/Users/IvS/Documents/2.Papers/2.WinterSim_ParametricCalibration/Results/Results_Missing_Full\"\n",
    "technique = \"ga\"\n",
    "directory = f\"./interaction/{technique}\"\n",
    "#Over folders\n",
    "for folder in os.listdir(directory):\n",
    "    if not folder.startswith('.'):\n",
    "        new_dir = directory+\"/\"+folder\n",
    "        technique = folder.split(\"_\")[-1]\n",
    "        percentage = folder.split(\"_\")[-3]\n",
    "        if os.path.isdir(new_dir):\n",
    "            for filename in os.listdir(new_dir):\n",
    "                if filename.endswith(\".pkl\"):\n",
    "                    f = new_dir+\"/\"+filename\n",
    "\n",
    "                    key = f\"{technique}_{percentage}\"\n",
    "\n",
    "                    with open(f, \"rb\") as file:\n",
    "                         info = pickle.load(file)\n",
    "                        \n",
    "                    seed = info[\"Model_info\"][\"parameters\"][\"seed\"]\n",
    "                    \n",
    "                    try:\n",
    "                        data[seed][key] = info\n",
    "                    except KeyError:\n",
    "                        data[seed] = {key: info}\n",
    "\n",
    "for k, v in data.items():\n",
    "    data[k] = dict(sorted(data[k].items(), key=lambda item: int(item[0].split('_')[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13ade5d-a878-49b4-b445-8875b2a09bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n",
      "11 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n",
      "21 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n",
      "16 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n",
      "6 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n",
      "26 dict_keys(['ga_28', 'ga_82', 'ga_88'])\n"
     ]
    }
   ],
   "source": [
    "# Check if complete\n",
    "for k, v in data.items():\n",
    "    print(k, data[k].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "166665bb-7b18-4203-818e-8af3219df570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get run time\n",
    "# for k, v in data.items():\n",
    "#     for perc, res in v.items():\n",
    "#         if perc == \"abc_0\":\n",
    "#             continue\n",
    "#         else:\n",
    "#             time = data[k][perc][\"Model_info\"][\"running_time\"]/60/60\n",
    "#             print(f\"Run time for {k} seed with {perc} is: {round(time, 2)} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebafac2-41e1-4825-9d9c-aecf0990a1bc",
   "metadata": {},
   "source": [
    "# Calculate Quality of Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21836c90-6b6f-4fe8-824f-e932b57f7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic parameters\n",
    "with open(r\"../../complex_stylized_supply_chain_model_generator/data/location_model_hpc_40000_cnhk_usa_airsea.pkl\", \"rb\") as f:\n",
    "    decision_variables = pickle.load(f)\n",
    "\n",
    "with open(r\"../../complex_stylized_supply_chain_model_generator/data/Ground_Truth_Graph_Topology_DF_CNHK_USA.pkl\", \"rb\") as f:\n",
    "    ground_truth_topology = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0eb37a8-4c1a-4d0a-ba2c-e6253287db2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_graph = ground_truth_topology[\"graph\"][0]\n",
    "\n",
    "for seed, attr in data.items():\n",
    "    for perc, res in attr.items():\n",
    "        sol_idx = data[seed][perc][\"Results\"][0][\"graph_structure\"]\n",
    "        sol_obj_value = data[seed][perc][\"Results\"][0][\"min_distance\"]\n",
    "        \n",
    "        sol_topology = decision_variables[round(sol_idx)]\n",
    "        sol_graph = sol_topology[\"graph\"]\n",
    "        \n",
    "        # combine ground truth and solutions\n",
    "        column_names = [\"edges\", \"nodes\", \"betweenness\", \"degree_centrality\", \"closeness_centrality\"]\n",
    "        df_sol_topology = pd.DataFrame.from_dict(sol_topology, orient=\"index\").T[column_names].rename(index={0: 'solution'})\n",
    "        df_gt_topology = ground_truth_topology[column_names].rename(index={0: 'ground_truth'})\n",
    "        \n",
    "        df_combined = pd.concat([df_gt_topology, df_sol_topology])\n",
    "        \n",
    "        # calculate differences\n",
    "        \n",
    "        diff_values = df_combined.loc['ground_truth'] - df_combined.loc['solution']\n",
    "        df_diff = pd.DataFrame([diff_values], index=['diff'])\n",
    "        \n",
    "        df_combined_diff = pd.concat([df_combined, df_diff])\n",
    "        \n",
    "        # calculate graph edit distance\n",
    "        ged=gm.GraphEditDistance(1,1,1,1) # all edit costs are equal to 1\n",
    "        result=ged.compare([gt_graph, sol_graph],None) \n",
    "        \n",
    "        distance = ged.distance(result)[1][0]\n",
    "        \n",
    "        # add to dictionary data\n",
    "        data[seed][perc][\"Quality_of_Fit\"] = {\"features\": df_combined_diff, \"graph_edit_distance\": distance, \"abs_dist\": np.sum(result)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ab47f11-83d8-4347-a505-384a0834c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = f\"./{technique}_{sparseness}/final_{technique}_{sparseness}_all_seeds.pkl\"\n",
    "# with open(file_name, \"wb\") as output:\n",
    "#     pickle.dump(data, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4c4e71-29f4-4b55-87cd-aca3a97733bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = directory + f\"/final_interaction_{technique}_all_seeds.pkl\"\n",
    "with open(file_name, \"wb\") as output:\n",
    "    pickle.dump(data, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
